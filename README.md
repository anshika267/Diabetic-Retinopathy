# Diabetic Retinopathy
BRIEF INTRODUCTION
	
In traditional  methods, the  process of  training and  testing flow starts from input of  the image,  then manual  feature extraction followed by training and  testing the  model for 
detection  and  classification.  But  the  advantage  of convolutional  neural  network  is  that  it  does  the  feature selection and feature extraction by itself from end-to-end. So,  there  is  no  need  to  manually  extract  the  features; instead input the images containing only those features and the rest is left up to the Convolutional Neural Network. The  Preprocessed  image  is  directly  fed  into  the Convolutional Neural Network for the reason stated above. 
And  it  does  all  the  feature  selection  and  extraction  by subsampling the parts of  the image through each layer  of convolution and pooling. Actually  there  are  many  numbers  of  convolution  and pooling layer for better classification. Finally, after  many passes into these  two layers it  reaches the  fully connected  layer,  the last  layer  of  Convolutional Neural Network, where it builds the filters for classification of  the  image  to  normal  and  abnormal.  Here  stops  the training  part.  The  testing  part  also  follows  the  same procedure but one more additional step it does is it performs an  operation  with  the  output  of  testing  image  values obtained from the fully connected layer with the values of filters which was constructed previously in the training part. 
If  a  match  with  higher score  is  found,  then  itâ€™s  classified accordingly. Then from the abnormal images, hemorrhages and Microaneurysms are segmented.


METHODOLOGY
Dataset
Indian Diabetic Retinopathy Image Dataset (IDRID) consists of three different tasks:
1.    Segmentation: This includes segmentation of four causes of retinopathy that includes, Microaneurysms (MA), Haemorrhages (HE), Hard Exudates (EX), and Soft Exudates (SE). It also includes images for the segmentation of the optic disc (OD).
2.    Disease Grading: This includes detection that how much the eye is affected by retinopathy and how much are the chances of macular edema due to retinopathy.
3.    Localization: This includes localization of optic disc and Fovea center
In the segmentation task, there is a total of 35136 images that are divided into training (28109 images) and test set (7027 images).
Pre-Processing
Before performing any task, images were pre-processed and three more datasets were generated. The first dataset was generated by enhancing the brightness, color and, contrast (BCC) of the original images. The second dataset was obtained by applying color jitters (CJ) to the original image.
In color jitters brightness, contrast and, a saturation of images are changed randomly. The third dataset was obtained by applying Contrast Limited Adaptive Histogram Equalization (CLAHE) on original images.

RESULTS
At first, images were pre-processed using different techniques. It can be seen from the images that features inside the image has been highlighted, for example, bright yellow spots in the processed images are the exudates. These spots were not as bright in the original image.

DISCUSSION AND CONCLUSION
Our study has shown that the five-class problem for national screening of DR can be approached using a CNN method. Our network has shown promising signs of being able to learn the features required to classify the fundus images, accurately classifying the majority of proliferative cases and cases with no DR. As in other studies using large datasets high specificity has come with a trade off of lower sensitivity. Our method produces comparable results to these previous methods without any feature-specific detection and using a much more general dataset. In practice images are sent to clinicians for grading and not accurately graded when the patient is in for screening. The trained CNN makes a quick diagnosis and instant response to a patient possible. The network also achieved these results with only one image per eye. 
The network has no issue learning to detect an image of a healthy eye. This is likely due to the large number of healthy eyes within the dataset. In training the learning required to classify the images at the extreme ends of the scale was significantly less. The issues came in making the network to distinguish between the mild, moderate and severe cases of DR.
Based on the results of the clinical experts, the model achieves an accuracy of 93.30%.
